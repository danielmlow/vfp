{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d35a732f-516d-4c8c-b7a9-5815ba9e05ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf62552e-d4db-40fa-81d2-b84f81015bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Authors: Daniel M. Low\n",
    "License: See license in github repository\n",
    "'''\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import soundfile as sf\n",
    "import os \n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aca4d1cd-33a8-493e-ac12-28c199baf509",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = datetime.datetime.utcnow().strftime('%y-%m-%dT%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baedb6bc-de6c-47ab-b05d-e4eab2a4ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# pd.options.display.width = 0\n",
    "\n",
    "\n",
    "on_colab = False\n",
    "\n",
    "if on_colab:\n",
    "  from google.colab import drive\n",
    "  project_name = 'project_name'\n",
    "  drive.mount('/content/drive')\n",
    "  input_dir = f'/content/drive/MyDrive/datum/{project_name}/data/input/'\n",
    "  output_dir = f'/content/drive/MyDrive/datum/{project_name}/data/output/'\n",
    "else:\n",
    "  input_dir = './data/input/'\n",
    "  output_dir = './data/output/'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89c49700-d57a-4955-ace0-a9d4b8a46dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = os.listdir(input_dir+'audios_16khz/')\n",
    "audio_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ace64f78-9742-4284-8e2d-2e371828ccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_files_speech = [n for n in audio_files if 'Speech_' in n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d31e1e-e9fd-4a5c-80e8-e19ac5529bab",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46c15027-9890-49e2-9576-9299ec9f20f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from importlib import reload\n",
    "# reload(cpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ace33aec-f5d4-4342-a460-3cf7c44dfd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import io\n",
    "import math\n",
    "import numpy.matlib\n",
    "\n",
    "\n",
    "\n",
    "# Hanning\n",
    "def hanning(N):\n",
    "    x = np.array([i/(N+1) for i in range(1, int(np.ceil(N/2))+1)])\n",
    "    w = 0.5-0.5*np.cos(2*np.pi*x)\n",
    "    w_rev = w[::-1]\n",
    "    return np.concatenate((w, w_rev[int((np.ceil(N % 2))):]))\n",
    "\n",
    "\n",
    "\n",
    "# function for computing cepstral peak prominence\n",
    "def cpp(x, fs, normOpt = 'line', dBScaleOpt = True):\n",
    "    \"\"\"\n",
    "    Computes cepstral peak prominence for a given signal \n",
    "    Parameters\n",
    "    Python implementation by Satvik Dixit and Daniel Low (MIT)\n",
    "    Based on MatLab implementation from John Kane kanejo@tcd.ie\n",
    "    based on Hillenbrand, J., Houde, R. A. (1996) ``Acoustic correlates of\n",
    "      breathy vocal quality: dysphonic voices and continuous\n",
    "      speech'', Journal of Speech and Hearing research 39:311-321\n",
    "\n",
    "    This function is part of the Covarep project: \n",
    "    http://covarep.github.io/covarep\n",
    "    \n",
    "    -----------\n",
    "    x: ndarray\n",
    "        The audio signal\n",
    "    fs: integer\n",
    "        The sampling frequency\n",
    "    normOpt: string\n",
    "        'line', 'mean' or 'nonorm' for selecting normalisation type\n",
    "    dBScaleOpt: binary\n",
    "        True or False for using decibel scale\n",
    "    Returns\n",
    "    -----------\n",
    "    cpp: ndarray\n",
    "        The CPP with time values \n",
    "    \"\"\"\n",
    "    # Settings\n",
    "    frame_length = int(np.round_(0.04*fs))\n",
    "    frame_shift = int(np.round_(0.01*fs))\n",
    "    half_len = int(np.round_(frame_length/2))\n",
    "    x_len = len(x)\n",
    "    frame_len = half_len*2 + 1\n",
    "    NFFT = 2**(math.ceil(np.log(frame_len)/np.log(2)))\n",
    "    quef = np.linspace(0, frame_len/1000, NFFT)\n",
    "\n",
    "    # Allowed quefrency range\n",
    "    pitch_range = [60, 333.3]\n",
    "    quef_lim = [int(np.round_(fs/pitch_range[1])),\n",
    "                int(np.round_(fs/pitch_range[0]))]\n",
    "    quef_seq = range(quef_lim[0]-1, quef_lim[1])\n",
    "\n",
    "    # Time samples\n",
    "    time_samples = np.array(\n",
    "        range(frame_length+1, x_len-frame_length+1, frame_shift))\n",
    "    N = len(time_samples)\n",
    "    frame_start = time_samples-half_len\n",
    "    frame_stop = time_samples+half_len\n",
    "\n",
    "    # High-pass filtering\n",
    "    HPfilt_b = [1 - 0.97]\n",
    "    x = signal.lfilter(HPfilt_b, 1, x)\n",
    "\n",
    "    # Frame matrix\n",
    "    frameMat = np.zeros([NFFT, N])\n",
    "    for n in range(0, N):\n",
    "        frameMat[0: frame_len, n] = x[frame_start[n]-1:frame_stop[n]]\n",
    "\n",
    "\n",
    "    win = hanning(frame_len)\n",
    "    winmat = numpy.matlib.repmat(win, N, 1).transpose()\n",
    "    frameMat = frameMat[0:frame_len, :]*winmat\n",
    "\n",
    "    # Cepstrum\n",
    "    SpecMat = np.abs(np.fft.fft(frameMat, axis=0))\n",
    "    SpecdB = 20*np.log10(SpecMat)\n",
    "    if dBScaleOpt:\n",
    "        ceps = 20*np.log10(np.abs(np.fft.fft(SpecdB, axis=0)))\n",
    "    else:\n",
    "        ceps = 2*np.log(np.abs(np.fft.fft(SpecdB, axis=0)))\n",
    "\n",
    "    # Finding the peak\n",
    "    ceps_lim = ceps[quef_seq, :]\n",
    "    ceps_max = ceps_lim.max(axis=0)\n",
    "    max_index = ceps_lim.argmax(axis=0)\n",
    "\n",
    "    # Normalisation\n",
    "    ceps_norm = np.zeros([N])\n",
    "    if normOpt == 'line':\n",
    "        for n in range(0, N):\n",
    "            p = np.polyfit(quef_seq, ceps_lim[:, n], 1)\n",
    "            ceps_norm[n] = np.polyval(p, quef_seq[max_index[n]])\n",
    "    elif normOpt == 'mean':\n",
    "        ceps_norm = np.mean(ceps_lim)\n",
    "\n",
    "    cpp = ceps_max-ceps_norm\n",
    "\n",
    "    return cpp, time_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d69abbd-7fc7-4044-8bc4-0f6fe1548443",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, fs = sf.read(input_dir+'audios_16khz/'+audio_files[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24862be9-b864-4038-b45e-23cb1318c723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 20s, sys: 3.15 s, total: 2min 23s\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "cpp_df = {}\n",
    "\n",
    "for audio_file in audio_files:\n",
    "    x, fs = sf.read(input_dir+'audios_16khz/'+audio_file)\n",
    "    cpp_i, time_samples_i = cpp(x, fs, normOpt = 'line', dBScaleOpt = True)\n",
    "    cpp_amean = np.mean(cpp_i) \n",
    "    cpp_stddevNorm = np.std(cpp_i) / np.mean(cpp_i)\n",
    "    cpp_percentile20, cpp_percentile50,cpp_percentile80 = np.percentile(cpp_i, [20,50,80])\n",
    "    cpp_df[audio_file] = [cpp_amean, cpp_stddevNorm, cpp_percentile20, cpp_percentile50,cpp_percentile80] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef01ab50-3503-4498-b63d-48b2feba21dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>cpp_amean</th>\n",
       "      <th>cpp_stddevNorm</th>\n",
       "      <th>cpp_percentile20</th>\n",
       "      <th>cpp_percentile80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VFP10_Speech</td>\n",
       "      <td>18.021915</td>\n",
       "      <td>0.246936</td>\n",
       "      <td>13.816228</td>\n",
       "      <td>22.591409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VFP10_Speech_1</td>\n",
       "      <td>18.435575</td>\n",
       "      <td>0.228489</td>\n",
       "      <td>14.486988</td>\n",
       "      <td>22.229799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VFP10_Speech_2</td>\n",
       "      <td>17.512815</td>\n",
       "      <td>0.266492</td>\n",
       "      <td>13.536888</td>\n",
       "      <td>22.317354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VFP10_Speech_3</td>\n",
       "      <td>18.321217</td>\n",
       "      <td>0.245712</td>\n",
       "      <td>14.002137</td>\n",
       "      <td>23.058219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VFP10_Vowel1</td>\n",
       "      <td>27.579498</td>\n",
       "      <td>0.076466</td>\n",
       "      <td>25.748448</td>\n",
       "      <td>29.352079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>VFPNorm9_Speech_2</td>\n",
       "      <td>16.389359</td>\n",
       "      <td>0.211420</td>\n",
       "      <td>13.639057</td>\n",
       "      <td>19.368173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>VFPNorm9_Speech_3</td>\n",
       "      <td>16.500820</td>\n",
       "      <td>0.214053</td>\n",
       "      <td>13.697178</td>\n",
       "      <td>19.013550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>VFPNorm9_Vowel1</td>\n",
       "      <td>29.302929</td>\n",
       "      <td>0.114723</td>\n",
       "      <td>26.911597</td>\n",
       "      <td>31.941200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>VFPNorm9_Vowel2</td>\n",
       "      <td>27.573875</td>\n",
       "      <td>0.077538</td>\n",
       "      <td>26.028163</td>\n",
       "      <td>29.060692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>VFPNorm9_Vowel3</td>\n",
       "      <td>25.736471</td>\n",
       "      <td>0.092166</td>\n",
       "      <td>24.173400</td>\n",
       "      <td>27.635959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1068 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename  cpp_amean  cpp_stddevNorm  cpp_percentile20  \\\n",
       "0          VFP10_Speech  18.021915        0.246936         13.816228   \n",
       "1        VFP10_Speech_1  18.435575        0.228489         14.486988   \n",
       "2        VFP10_Speech_2  17.512815        0.266492         13.536888   \n",
       "3        VFP10_Speech_3  18.321217        0.245712         14.002137   \n",
       "4          VFP10_Vowel1  27.579498        0.076466         25.748448   \n",
       "...                 ...        ...             ...               ...   \n",
       "1063  VFPNorm9_Speech_2  16.389359        0.211420         13.639057   \n",
       "1064  VFPNorm9_Speech_3  16.500820        0.214053         13.697178   \n",
       "1065    VFPNorm9_Vowel1  29.302929        0.114723         26.911597   \n",
       "1066    VFPNorm9_Vowel2  27.573875        0.077538         26.028163   \n",
       "1067    VFPNorm9_Vowel3  25.736471        0.092166         24.173400   \n",
       "\n",
       "      cpp_percentile80  \n",
       "0            22.591409  \n",
       "1            22.229799  \n",
       "2            22.317354  \n",
       "3            23.058219  \n",
       "4            29.352079  \n",
       "...                ...  \n",
       "1063         19.368173  \n",
       "1064         19.013550  \n",
       "1065         31.941200  \n",
       "1066         29.060692  \n",
       "1067         27.635959  \n",
       "\n",
       "[1068 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpp_df = pd.DataFrame(cpp_df).T.reset_index()\n",
    "cpp_df.columns = ['filename', 'cpp_amean', 'cpp_stddevNorm', 'cpp_percentile20', 'cpp_percentile50','cpp_percentile80']\n",
    "cpp_df = cpp_df.drop('cpp_percentile50', axis=1) # very similar to mean\n",
    "cpp_df['filename'] = [n.replace('.wav', '') for n in cpp_df['filename'].values]\n",
    "cpp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cdc0cb08-e4d5-49b0-bb18-565ce9046344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>cpp_amean</th>\n",
       "      <th>cpp_stddevNorm</th>\n",
       "      <th>cpp_percentile20</th>\n",
       "      <th>cpp_percentile80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VFP10_Speech</td>\n",
       "      <td>18.021915</td>\n",
       "      <td>0.246936</td>\n",
       "      <td>13.816228</td>\n",
       "      <td>22.591409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VFP10_Speech1</td>\n",
       "      <td>18.435575</td>\n",
       "      <td>0.228489</td>\n",
       "      <td>14.486988</td>\n",
       "      <td>22.229799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VFP10_Speech2</td>\n",
       "      <td>17.512815</td>\n",
       "      <td>0.266492</td>\n",
       "      <td>13.536888</td>\n",
       "      <td>22.317354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VFP10_Speech3</td>\n",
       "      <td>18.321217</td>\n",
       "      <td>0.245712</td>\n",
       "      <td>14.002137</td>\n",
       "      <td>23.058219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VFP10_Vowel1</td>\n",
       "      <td>27.579498</td>\n",
       "      <td>0.076466</td>\n",
       "      <td>25.748448</td>\n",
       "      <td>29.352079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>VFPNorm9_Speech2</td>\n",
       "      <td>16.389359</td>\n",
       "      <td>0.211420</td>\n",
       "      <td>13.639057</td>\n",
       "      <td>19.368173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>VFPNorm9_Speech3</td>\n",
       "      <td>16.500820</td>\n",
       "      <td>0.214053</td>\n",
       "      <td>13.697178</td>\n",
       "      <td>19.013550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>VFPNorm9_Vowel1</td>\n",
       "      <td>29.302929</td>\n",
       "      <td>0.114723</td>\n",
       "      <td>26.911597</td>\n",
       "      <td>31.941200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>VFPNorm9_Vowel2</td>\n",
       "      <td>27.573875</td>\n",
       "      <td>0.077538</td>\n",
       "      <td>26.028163</td>\n",
       "      <td>29.060692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>VFPNorm9_Vowel3</td>\n",
       "      <td>25.736471</td>\n",
       "      <td>0.092166</td>\n",
       "      <td>24.173400</td>\n",
       "      <td>27.635959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1068 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename  cpp_amean  cpp_stddevNorm  cpp_percentile20  \\\n",
       "0         VFP10_Speech  18.021915        0.246936         13.816228   \n",
       "1        VFP10_Speech1  18.435575        0.228489         14.486988   \n",
       "2        VFP10_Speech2  17.512815        0.266492         13.536888   \n",
       "3        VFP10_Speech3  18.321217        0.245712         14.002137   \n",
       "4         VFP10_Vowel1  27.579498        0.076466         25.748448   \n",
       "...                ...        ...             ...               ...   \n",
       "1063  VFPNorm9_Speech2  16.389359        0.211420         13.639057   \n",
       "1064  VFPNorm9_Speech3  16.500820        0.214053         13.697178   \n",
       "1065   VFPNorm9_Vowel1  29.302929        0.114723         26.911597   \n",
       "1066   VFPNorm9_Vowel2  27.573875        0.077538         26.028163   \n",
       "1067   VFPNorm9_Vowel3  25.736471        0.092166         24.173400   \n",
       "\n",
       "      cpp_percentile80  \n",
       "0            22.591409  \n",
       "1            22.229799  \n",
       "2            22.317354  \n",
       "3            23.058219  \n",
       "4            29.352079  \n",
       "...                ...  \n",
       "1063         19.368173  \n",
       "1064         19.013550  \n",
       "1065         31.941200  \n",
       "1066         29.060692  \n",
       "1067         27.635959  \n",
       "\n",
       "[1068 rows x 5 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to match formatting of egemaps filenames\n",
    "cpp_df['filename'] = [n.replace('Speech_', 'Speech') for n in cpp_df['filename'].values]\n",
    "cpp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d99dfa-49d5-4479-b8d9-2f8f9a60bda9",
   "metadata": {},
   "source": [
    "### Add to egemaps features DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "69a48363-d4ba-49a6-a31c-d1bef0afcedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# egemaps features\n",
    "egemaps_filenames = ['egemaps_vector_both.csv',\n",
    "                    'egemaps_vector_speech.csv',\n",
    "                    'egemaps_vector_vowel.csv'\n",
    "                   ]\n",
    "\n",
    "egemaps_features_df = {}\n",
    "for i in egemaps_filenames:\n",
    "    df_i = pd.read_csv(input_dir+'features/'+i, index_col = 0)\n",
    "    egemaps_features_df[i]=df_i\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bbb31c7f-2633-4179-beb0-6fb47a97d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename, df_i in egemaps_features_df.items():\n",
    "    df_i_cpp = df_i.merge(cpp_df, on = ['filename'], how='inner')\n",
    "    df_i_cpp.to_csv(input_dir+'features/'+filename.replace('.csv', '_cpp.csv'))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d596422-dc1b-4fe2-ba05-09829e689212",
   "metadata": {},
   "source": [
    "# Bootstrapping classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e958079-0343-4867-b1f4-d8831a4bd704",
   "metadata": {
    "id": "3Fp0uYpuCxav"
   },
   "outputs": [],
   "source": [
    "\n",
    "models = [\n",
    "    LogisticRegressionCV(solver='liblinear', penalty = 'l1', max_iter = 100),\n",
    "    SGDClassifier(loss='log', penalty=\"elasticnet\", early_stopping=True, max_iter = 5000),\n",
    "    MLPClassifier(alpha = 1, max_iter= 1000),\n",
    "    RandomForestClassifier(n_estimators= 100)\n",
    "]\n",
    "\n",
    "\n",
    "names = ['LogisticRegressionCV', 'SGDClassifier', \"MLPClassifier\",\"RandomForestClassifier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40cc8b66-f724-46ce-beec-e61a184cd7d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1cIEh3jCBvnT",
    "outputId": "40e0fc58-1df7-4578-b77b-29ddc6447164"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech \n",
      "====\n",
      "\n",
      "permute True\n",
      "LogisticRegressionCV .5\n",
      "MLPClassifier .48\n",
      "RandomForestClassifier .57\n",
      "SGDClassifier .51\n",
      "\n",
      "permute False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.86 (.75–.93; )</td>\n",
       "      <td>.86 (.75–.93; )</td>\n",
       "      <td>.79 (.67–.87; )</td>\n",
       "      <td>.85 (.55–.92; )</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0                1                       2  \\\n",
       "0  LogisticRegressionCV    MLPClassifier  RandomForestClassifier   \n",
       "1       .86 (.75–.93; )  .86 (.75–.93; )         .79 (.67–.87; )   \n",
       "\n",
       "                 3  \n",
       "0    SGDClassifier  \n",
       "1  .85 (.55–.92; )  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vowel \n",
      "====\n",
      "\n",
      "permute True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/danielmlow/miniconda3/envs/pydra/lib/python3.7/site-packages/sklearn/svm/_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegressionCV .5\n",
      "MLPClassifier .48\n",
      "RandomForestClassifier .51\n",
      "SGDClassifier .48\n",
      "\n",
      "permute False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.87 (.8–.95; )</td>\n",
       "      <td>.87 (.79–.95; )</td>\n",
       "      <td>.82 (.73–.91; )</td>\n",
       "      <td>.85 (.71–.94; )</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0                1                       2  \\\n",
       "0  LogisticRegressionCV    MLPClassifier  RandomForestClassifier   \n",
       "1        .87 (.8–.95; )  .87 (.79–.95; )         .82 (.73–.91; )   \n",
       "\n",
       "                 3  \n",
       "0    SGDClassifier  \n",
       "1  .85 (.71–.94; )  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both \n",
      "====\n",
      "\n",
      "permute True\n",
      "LogisticRegressionCV .51\n",
      "MLPClassifier .53\n",
      "RandomForestClassifier .53\n",
      "SGDClassifier .51\n",
      "\n",
      "permute False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>SGDClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.81 (.73–.89; )</td>\n",
       "      <td>.85 (.75–.91; )</td>\n",
       "      <td>.79 (.71–.86; )</td>\n",
       "      <td>.78 (.47–.89; )</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0                1                       2  \\\n",
       "0  LogisticRegressionCV    MLPClassifier  RandomForestClassifier   \n",
       "1       .81 (.73–.89; )  .85 (.75–.91; )         .79 (.71–.86; )   \n",
       "\n",
       "                 3  \n",
       "0    SGDClassifier  \n",
       "1  .78 (.47–.89; )  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 8s, sys: 3min 19s, total: 6min 27s\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "toy = False\n",
    "\n",
    "for df_name, task_type_df in zip(['speech', 'vowel', 'both'], [\n",
    "    'egemaps_vector_speech_cpp.csv',\n",
    "    'egemaps_vector_vowel_cpp.csv', \n",
    "    'egemaps_vector_both_cpp.csv']):\n",
    "    cpp_df = pd.read_csv(input_dir+f'features/{task_type_df}', index_col = 0)\n",
    "    print(df_name, '\\n====')\n",
    "\n",
    "    for null_model in [True, False]:\n",
    "        print('\\npermute', null_model)\n",
    "    \n",
    "        if toy:\n",
    "          n_bootstraps = 3\n",
    "        else:\n",
    "          n_bootstraps = 50\n",
    "\n",
    "        # bs = cross_validation.Bootstrap(len(y), n_bootstraps=n_bootstraps, random_state=123,n_test = 0.2) # or add source code\n",
    "\n",
    "\n",
    "        variables = ['cpp_amean', 'cpp_stddevNorm', 'cpp_percentile20', 'cpp_percentile80']\n",
    "        X = cpp_df[variables].values\n",
    "        y = cpp_df['target'].values\n",
    "        if null_model:\n",
    "            y = np.random.permutation(y) #CHECK\n",
    "        groups = cpp_df['sid'].values\n",
    "\n",
    "        y_pred_all = {}\n",
    "        roc_auc_all = {}\n",
    "        for model, name in zip(models, names):\n",
    "          y_pred_all[name] = []\n",
    "          roc_auc_all[name] = []\n",
    "          pipe = Pipeline(steps=[\n",
    "                  ('scaler', StandardScaler()), \n",
    "                  ('model', model)])\n",
    "\n",
    "          # ## Performing bootstrapping\n",
    "          # for i in range(n_bootstraps):\n",
    "          #     #Split the data into training and testing set\n",
    "          #     from sklearn.model_selection import train_test_split\n",
    "          #     # Chaning the seed value for each iteration\n",
    "          #     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42+i)\n",
    "\n",
    "          ## Performing bootstrapping\n",
    "          splitter = GroupShuffleSplit(n_splits=50, test_size=0.2, random_state=42)\n",
    "          for i, (train_index, test_index) in enumerate(splitter.split(X, y, groups)):\n",
    "\n",
    "              X_train, X_test = X[train_index], X[test_index]\n",
    "              y_train, y_test = y[train_index], y[test_index]\n",
    "              pipe.fit(X_train,y_train)     \n",
    "\n",
    "              # # Evaluate\n",
    "              # y_proba = pipe.predict_proba(X_test)       # Get predicted probabilities\n",
    "              # y_proba_1 = y_proba[:,1]\n",
    "              # y_pred = np.argmax(y_proba, axis=1) \n",
    "              # roc_auc = metrics.roc_auc_score(y_test, y_proba_1)  \n",
    "\n",
    "              y_pred = pipe.predict(X_test) \n",
    "              roc_auc = metrics.roc_auc_score(y_test, y_pred)  # ROC AUC takes probabilities but here we match what pydra-ml does: https://github.com/nipype/pydra-ml/issues/56\n",
    "\n",
    "              y_pred_all[name].append(y_pred)\n",
    "              roc_auc_all[name].append(roc_auc)\n",
    "\n",
    "        results_i = []\n",
    "        for name in ['LogisticRegressionCV','MLPClassifier','RandomForestClassifier','SGDClassifier']:\n",
    "          scores = roc_auc_all.get(name)\n",
    "          roc_auc_median = np.round(np.median(scores),2)\n",
    "          roc_auc_5 = np.round(np.percentile(scores, 5),2)\n",
    "          roc_auc_95 = np.round(np.percentile(scores, 95),2)\n",
    "          results_str = f'{roc_auc_median} ({roc_auc_5}–{roc_auc_95}; )'\n",
    "          results_str = results_str.replace('0.', '.')\n",
    "          results_i.append([name, results_str])\n",
    "            \n",
    "          if null_model:\n",
    "            print(name, str(roc_auc_median).replace('0.', '.'))\n",
    "        if not null_model:\n",
    "            results_i_df = pd.DataFrame(results_i, ).T\n",
    "            display(results_i_df)\n",
    "            results_i_df.to_csv(output_dir+f'cpp/results_cpp_{df_name}_permute-{null_model}_{ts}.csv')\n",
    "\n",
    "            \n",
    "                \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc62c440-c0d0-4c4e-9efd-effd6ae04340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
